{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T15:30:03.634114Z",
     "start_time": "2017-08-23T15:30:03.629294Z"
    }
   },
   "source": [
    "# Exercise Set 8: Introduction to Web Scraping\n",
    "\n",
    "*Afternoon, August 16, 2018*\n",
    "\n",
    "In this Exercise Set we shall practice our webscraping skills utiilizing only basic python. We shall cover variations between static and dynamic pages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Section 8.1: Scraping Jobnet.dk\n",
    "\n",
    "This exercise you get to practice locating the request that the JavaScript sends to get the job data that it builds the joblistings from. You should use the **>Network Monitor<** tool in your browser.\n",
    "\n",
    "Furthermore you practice spotting how the pagination is done, without clicking on the next page button, but instead changing a small parameter in the URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.1.1:** Hit the joblisting webpage here: https://job.jobnet.dk/CV and locate the request that gets the joblisting data using the a tool called the **>Network Monitor<**. To do this open monitor tool and press the search button on the website. Go to the _network_ pane in the monitor and look at the results. Which two _methods_ does your browser use to communicate with the webserver? What does status code 200 mean?\n",
    ">\n",
    ">> _Hint:_ The network monitor is launched by pressing ctrl+shift+i in most browsers. Filter by XHR files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GET\n",
    "- POST\n",
    "- Status code 200 - the request was recieved and understood and is being processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.1.2.:** Use the `request` module to collect the first page of job postings and unpack the relevant `json` data into a `pandas` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Expression', 'Facets', 'JobPositionPostings', 'TotalResultCount'])\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "url = 'https://job.jobnet.dk/CV/FindWork/Search?Offset=0&SortValue=BestMatch'\n",
    "response = requests.get(url)\n",
    "json = json.loads(response.text)\n",
    "print(json.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.1.3.:** Store and print the 'TotalResultCount' value for later use. Also create a dataframe from the 'JobPositionPostings' field in the json. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "df_jpp = pd.DataFrame(json['JobPositionPostings'])\n",
    "trc = json['TotalResultCount']\n",
    "print(trc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.1.4:** This exercise is about paging the results. We need to understand the websites pagination scheme. Scroll down the webpage and press the next page button. Describe how the parameters of the url changes as you turn the pages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pagination scheme is controlled by the variable offset. Every page contains 20 job positions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.1.5:** Design a`for` loop using the `range` function that changes this paging parameter in the URL. Use the TotalResultCount parameter from before to define the limits of the range function. Store these urls in a container. \n",
    ">\n",
    ">**Bonus** Change the SortValue parameter from BestMatch to CreationDate, to make the sorting amendable to updating results daily.\n",
    ">\n",
    ">> _Hint:_ See that the parameter is an offset and that this relates to the number of results pr. call made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = []\n",
    "for i in range(0, trc, 20):\n",
    "    url = 'https://job.jobnet.dk/CV/FindWork/Search?Offset=' + str(i) + '&SortValue=CreationDate'\n",
    "    pages.append(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.1.6:** Pick 20 random links using the `choice` function in the `random` module;  collect the links using the `request` module. Also use the `time.sleep()` function to limit the rate of your calls. Make sure to save the links already collected in a `set()` container to avoid having to reload links already collected. ***extra***: monitor the time left to completing the loop by using `tqdm.tqdm()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "set_pages = set(pages)\n",
    "set_pages20 = set(random.sample(set_pages,20))\n",
    "\n",
    "jsons = []\n",
    "for link in set_pages20:\n",
    "    response = requests.get(link)\n",
    "    json = response.json()\n",
    "    jsons.append(json)\n",
    "    time.sleep(1)\n",
    "\n",
    "len(jsons)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.1.7:** Load all the results into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for json in jsons:\n",
    "    df_load = pd.DataFrame(json['JobPositionPostings'])\n",
    "    df = pd.concat([df, df_load])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Section 8.2: Scraping Trustpilot.com\n",
    "Now for a slightly more elaborate, yet still simple scraping problem. Here we want to scrape trustpilot for user reviews. This data is very nice since it provides free labeled data (rating) to train a machine learning model to understand positive and negative sentiment. \n",
    "\n",
    "Here you will practice crawling a website collecting the links to each company review page, and finally locate another behind the scenes JavaScript request that gets the review data in a neat json format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.2.1:** Visit the https://www.trustpilot.com/ website and locate the categories page. From this page you find links to company listings. Get the category page using the `requests` module and extract each link to a specific category page from the HTML. This can be done using the basic python `.split()` string method. Make sure only links within the ***/categories/*** section are kept, checking each string using the ```if 'pattern' in string``` condition. \n",
    ">\n",
    ">> *Hint:* The links are relative. You need to add the domain name\n",
    ">>\n",
    ">> *Hint #2:* You will need to convert the page response to a string, using the `.text` property.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://support.trustpilot.com/hc/categories/200128688-Support-for-Reviewers',\n",
       " 'https://www.trustpilot.com/categories/animals_and_pets',\n",
       " 'https://www.trustpilot.com/categories/art',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion',\n",
       " 'https://www.trustpilot.com/categories/cloud_computing',\n",
       " 'https://www.trustpilot.com/categories/companies',\n",
       " 'https://www.trustpilot.com/categories/computer',\n",
       " 'https://www.trustpilot.com/categories/craftsman',\n",
       " 'https://www.trustpilot.com/categories/electronics',\n",
       " 'https://www.trustpilot.com/categories/entertainment',\n",
       " 'https://www.trustpilot.com/categories/erotic',\n",
       " 'https://www.trustpilot.com/categories/food_beverage',\n",
       " 'https://www.trustpilot.com/categories/gambling',\n",
       " 'https://www.trustpilot.com/categories/health_wellbeing',\n",
       " 'https://www.trustpilot.com/categories/home_garden',\n",
       " 'https://www.trustpilot.com/categories/kids',\n",
       " 'https://www.trustpilot.com/categories/legal_services',\n",
       " 'https://www.trustpilot.com/categories/leisure',\n",
       " 'https://www.trustpilot.com/categories/mobile_internet',\n",
       " 'https://www.trustpilot.com/categories/money',\n",
       " 'https://www.trustpilot.com/categories/online_services',\n",
       " 'https://www.trustpilot.com/categories/other',\n",
       " 'https://www.trustpilot.com/categories/public_services',\n",
       " 'https://www.trustpilot.com/categories/sport',\n",
       " 'https://www.trustpilot.com/categories/tobacco-products',\n",
       " 'https://www.trustpilot.com/categories/transportation',\n",
       " 'https://www.trustpilot.com/categories/travel_holidays',\n",
       " 'https://www.trustpilot.com/categories/utilities'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://www.trustpilot.com/categories'\n",
    "response = requests.get(url)\n",
    "link_locations = response.text.split('href=\"')[1:]\n",
    "\n",
    "links = set()\n",
    "for link in link_locations:\n",
    "    path = link.split('\"')[0]\n",
    "    if 'trustpilot.com' in path:\n",
    "        path = path\n",
    "    else:\n",
    "        path = 'https://www.trustpilot.com' + path\n",
    "    if '/categories/' in path:\n",
    "        links.add(path)\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.2.2:** Get one of the category section links (any one will do). Write a function to extract the links to the company review pages from the HTML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.trustpilot.com/review/soulrevolver.com',\n",
       " 'https://www.trustpilot.com/review/ipromo.com',\n",
       " 'https://www.trustpilot.com/review/www.primestyle.com',\n",
       " 'https://www.trustpilot.com/review/www.baunat.com',\n",
       " 'https://www.trustpilot.com/review/www.firmoo.com',\n",
       " 'https://www.trustpilot.com/review/leibish.com',\n",
       " 'https://www.trustpilot.com/review/advertscreenprinting.com',\n",
       " 'https://www.trustpilot.com/review/www.swissluxury.com',\n",
       " 'https://www.trustpilot.com/review/coutureusa.com',\n",
       " 'https://www.trustpilot.com/review/www.phigora.com',\n",
       " 'https://www.trustpilot.com/review/www.brilliance.com',\n",
       " 'https://www.trustpilot.com/review/www.queensboro.com',\n",
       " 'https://www.trustpilot.com/review/briangavindiamonds.com',\n",
       " 'https://www.trustpilot.com/review/tinylittlemonster.com',\n",
       " 'https://www.trustpilot.com/review/greenlakejewelry.com',\n",
       " 'https://www.trustpilot.com/review/redtunashirtclub.com',\n",
       " 'https://www.trustpilot.com/review/www.shopworn.com',\n",
       " 'https://www.trustpilot.com/review/www.thenaturalsapphirecompany.com',\n",
       " 'https://www.trustpilot.com/review/wholesalescreenprinting.com',\n",
       " 'https://www.trustpilot.com/review/overnightdiamonds.com']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.trustpilot.com/categories/clothes_fashion'\n",
    "response = requests.get(url)\n",
    "if response.ok:\n",
    "    html = response.text\n",
    "else:\n",
    "    print('error')\n",
    "\n",
    "def get_links(html):\n",
    "    links = set()\n",
    "    for link in html.split('href=\"')[1:]:\n",
    "        path = link.split('\"')[0]\n",
    "        if 'trustpilot.com' in path:\n",
    "            path = path\n",
    "        else:\n",
    "            path = 'https://www.trustpilot.com' + path\n",
    "        links.add(path)\n",
    "    return links\n",
    "\n",
    "def get_company_links(html):\n",
    "    return [link for link in get_links(html) if '/review/' in link] # check if the /review/ pattern is in the link and keep if true\n",
    "\n",
    "\n",
    "company_links = get_company_links(html)\n",
    "company_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.2.3:** Figure out how the pagination is done, by following how the url changes when pressing the **next page**-button to obtain more company listings. Write a function that builds links to paging all the company listing results of each category. This includes parsing the number of subpages of each category and changing the correct parameter in the url.\n",
    ">\n",
    ">> *Hint:* Find the maximum number of result pages, right before the next page button and make a loop change the page parameter of the url.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.trustpilot.com/categories/clothes_fashion',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=2',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=3',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=4',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=5',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=6',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=7',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=8',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=9',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=10',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=11',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=12',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=13',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=14',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=15',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=16',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=17',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=18',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=19',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=20',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=21',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=22',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=23',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=24',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=25',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=26',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=27',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=28',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=29',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=30',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=31',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=32',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=33',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=34',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=35',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=36',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=37',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=38',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=39',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=40',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=41',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=42',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=43',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=44',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=45',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=46',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=47',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=48',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=49',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=50',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=51',\n",
       " 'https://www.trustpilot.com/categories/clothes_fashion?page=52']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_category_pages(category_link): \n",
    "    # Get the broad category html\n",
    "    response = requests.get(category_link)\n",
    "    if response.ok:\n",
    "        html = response.text\n",
    "    else:\n",
    "        print('error')\n",
    "        return False\n",
    "    \n",
    "    # Get the links in this html\n",
    "    links = get_links(html)\n",
    "\n",
    "    # find the max_page number.\n",
    "    page_links = [link for link in links if '?page=' in link] # check if the paging parameter is in the link\n",
    "    if len(page_links)==0: # no pages.\n",
    "        return [category_link]\n",
    "    n_pages = max([int(link.split('page=')[-1]) for link in page_links]) # extract the page value and take the max\n",
    "    \n",
    "    paging_links = [category_link] # define container and store the original result page\n",
    "    \n",
    "    q = category_link+'?page=%d' # define the varying parameter string.\n",
    "\n",
    "    for num in range(2,n_pages+1): # build the links.\n",
    "        paging_links.append(q%num)\n",
    "    \n",
    "    return paging_links\n",
    "\n",
    "pages = get_all_category_pages(url)\n",
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.2.4:** Loop through all categories and build the paging links using the above defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.trustpilot.com/categories/leisure\n",
      "https://www.trustpilot.com/categories/animals_and_pets\n",
      "https://www.trustpilot.com/categories/utilities\n",
      "https://www.trustpilot.com/categories/computer\n",
      "https://www.trustpilot.com/categories/electronics\n",
      "https://www.trustpilot.com/categories/online_services\n",
      "https://www.trustpilot.com/categories/gambling\n",
      "https://www.trustpilot.com/categories/other\n",
      "https://www.trustpilot.com/categories/craftsman\n",
      "https://www.trustpilot.com/categories/transportation\n",
      "https://www.trustpilot.com/categories/art\n",
      "https://www.trustpilot.com/categories/erotic\n",
      "https://www.trustpilot.com/categories/health_wellbeing\n",
      "https://www.trustpilot.com/categories/kids\n",
      "https://www.trustpilot.com/categories/companies\n",
      "https://www.trustpilot.com/categories/cloud_computing\n",
      "https://www.trustpilot.com/categories/travel_holidays\n",
      "https://www.trustpilot.com/categories/food_beverage\n",
      "https://www.trustpilot.com/categories/home_garden\n",
      "https://www.trustpilot.com/categories/legal_services\n",
      "https://www.trustpilot.com/categories/sport\n",
      "https://www.trustpilot.com/categories/mobile_internet\n",
      "https://www.trustpilot.com/categories/tobacco-products\n",
      "https://www.trustpilot.com/categories/clothes_fashion\n",
      "https://www.trustpilot.com/categories/entertainment\n",
      "https://www.trustpilot.com/categories/public_services\n",
      "https://www.trustpilot.com/categories/money\n"
     ]
    }
   ],
   "source": [
    "# Build the paging links\n",
    "company_listings = []\n",
    "\n",
    "for link in links: \n",
    "    if 'support.trustpilot' in link:\n",
    "        continue\n",
    "    company_listings+=get_all_category_pages(link)\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.2.5:** Randomly pick one of category listing links you have generated, and get the links to the companies listed using the other function defined. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex.8.2.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.2.6:** Visit one of these links and inspect the **>Network Monitor<** to locate the request that loads the review data. Use the requests module to retrieve this link and unpack the json results to a pandas DataFrame.\n",
    ">\n",
    ">> _Hint:_ Look for a request which sends a the link to a file called `jsonId`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Answer to Ex.8.2.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on coming this far. By now you are almost - still need to figure out how to page the reviews and to find the company ID in the html -, ready to deploy a scraper collecting all reviews on trustpilot. \n",
    "If you wanna see just how valuable such data could be visit the follow blogpost: https://blog.openai.com/unsupervised-sentiment-neuron/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
